{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the database\n",
    "# data = pd.DataFrame.from_records(Appointment.objects.values(\n",
    "#     'doctor', 'appointment_date', 'start_time', 'end_time', 'status', 'reason_for_visit'\n",
    "# ))\n",
    "data = pd.read_csv('appointments_data.csv')\n",
    "# Feature engineering\n",
    "data['appointment_date'] = pd.to_datetime(data['appointment_date'])\n",
    "data['weekday'] = data['appointment_date'].dt.day_name()\n",
    "data['hour'] = pd.to_datetime(data['start_time'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Map status to binary\n",
    "data['is_completed'] = data['status'].map({'COMPLETED': 1, 'SCHEDULED': 1, 'CANCELLED': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.31      0.28        48\n",
      "           1       0.77      0.72      0.74       152\n",
      "\n",
      "    accuracy                           0.62       200\n",
      "   macro avg       0.51      0.51      0.51       200\n",
      "weighted avg       0.65      0.62      0.63       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Features and target\n",
    "X = data[['doctor', 'weekday', 'hour']]\n",
    "y = data['is_completed']\n",
    "\n",
    "# Encode categorical features\n",
    "X = pd.get_dummies(X, columns=['doctor', 'weekday'], drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       190\n",
      "\n",
      "    accuracy                           1.00       190\n",
      "   macro avg       1.00      1.00      1.00       190\n",
      "weighted avg       1.00      1.00      1.00       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate daily appointment counts\n",
    "daily_data = data.groupby(['doctor', 'appointment_date']).size().reset_index(name='appointment_count')\n",
    "\n",
    "# Add weekday information\n",
    "daily_data['weekday'] = daily_data['appointment_date'].dt.day_name()\n",
    "\n",
    "# Set demand threshold (e.g., top 25% of appointments)\n",
    "threshold = daily_data['appointment_count'].quantile(0.75)\n",
    "daily_data['high_demand'] = (daily_data['appointment_count'] >= threshold).astype(int)\n",
    "\n",
    "# Features and target\n",
    "X = pd.get_dummies(daily_data[['doctor', 'weekday']], drop_first=True)\n",
    "y = daily_data['high_demand']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       190\n",
      "\n",
      "    accuracy                           1.00       190\n",
      "   macro avg       1.00      1.00      1.00       190\n",
      "weighted avg       1.00      1.00      1.00       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best parameters from GridSearchCV\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    min_samples_split=2, \n",
    "    class_weight='balanced', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model again with the best parameters\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doctor appointment_date  appointment_count\n",
      "0       1       2020-01-04                  1\n",
      "1       1       2020-01-17                  1\n",
      "2       1       2020-01-21                  1\n",
      "3       1       2020-01-25                  1\n",
      "4       1       2020-01-31                  1\n"
     ]
    }
   ],
   "source": [
    "# Aggregate daily appointment counts for each doctor\n",
    "daily_counts = data.groupby(['doctor', 'appointment_date']).size().reset_index(name='appointment_count')\n",
    "\n",
    "# Check the aggregated data\n",
    "print(daily_counts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doctor  patient appointment_date start_time  end_time     status  \\\n",
      "0       1       54       2021-03-10   08:59:13  14:23:36  COMPLETED   \n",
      "1       4       52       2024-08-29   10:07:47  18:52:30  CANCELLED   \n",
      "2       3       28       2024-11-20   00:13:55  21:30:46  CANCELLED   \n",
      "3       3       16       2024-11-16   03:53:35  19:54:46  CANCELLED   \n",
      "4       1        7       2020-01-17   11:27:06  17:19:36  COMPLETED   \n",
      "\n",
      "                                    reason_for_visit  created_at  updated_at  \\\n",
      "0   However ability many pick. Life bad smile large.  2025-01-24  2025-01-14   \n",
      "1  Various why paper describe understand. Floor m...  2025-01-26  2025-01-24   \n",
      "2  Least his rule concern lose yes traditional. S...  2025-01-11  2025-01-01   \n",
      "3  Occur fall who morning plant truth perform. Be...  2025-01-11  2025-01-20   \n",
      "4  Probably thank audience weight establish docto...  2025-01-15  2025-01-01   \n",
      "\n",
      "     weekday  hour  is_completed  is_high_demand  \n",
      "0  Wednesday     8             1           False  \n",
      "1   Thursday    10             0           False  \n",
      "2  Wednesday     0             0           False  \n",
      "3   Saturday     3             0           False  \n",
      "4     Friday    11             1           False  \n"
     ]
    }
   ],
   "source": [
    "# Set a threshold for high demand (e.g., 5 appointments per day)\n",
    "threshold = 5\n",
    "\n",
    "# Add a new column for high-demand days\n",
    "daily_counts['is_high_demand'] = daily_counts['appointment_count'] > threshold\n",
    "\n",
    "# Merge this information back to your original data\n",
    "data = pd.merge(data, daily_counts[['doctor', 'appointment_date', 'is_high_demand']], on=['doctor', 'appointment_date'], how='left')\n",
    "\n",
    "# Check the updated data\n",
    "print(data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
